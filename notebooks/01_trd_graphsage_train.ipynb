{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ TRD-GraphSAGE: Temporal GNN for Fraud Detection\n",
    "\n",
    "**Leakage-Safe Temporal Graph Neural Network with Time-Relaxed Directed (TRD) Sampling**\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Overview\n",
    "\n",
    "This notebook implements and trains **TRD-GraphSAGE**, a temporal Graph Neural Network that enforces strict temporal constraints:\n",
    "- **No future leakage**: For target node at time `t*`, only neighbors with `timestamp ‚â§ t*` are sampled\n",
    "- **Directed sampling**: Separate handling of incoming and outgoing edges\n",
    "- **Temporal splits**: Train/Val/Test based on transaction timestamps\n",
    "\n",
    "### Key Innovation\n",
    "Unlike static GNNs that aggregate from all neighbors regardless of time, TRD-GraphSAGE respects transaction chronology, making predictions realistic and deployment-ready.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objectives\n",
    "\n",
    "1. Load Elliptic++ Bitcoin transaction dataset\n",
    "2. Implement TRD-GraphSAGE with temporal constraints\n",
    "3. Train with early stopping on validation PR-AUC\n",
    "4. Evaluate on test set and compare with baseline metrics\n",
    "5. Export results for comparison report\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Kaggle Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed on Kaggle)\n",
    "# !pip install torch torch-geometric -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve, \n",
    "    roc_curve, \n",
    "    auc,\n",
    "    f1_score,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üîß Using device: {device}\")\n",
    "print(f\"üî¢ PyTorch version: {torch.__version__}\")\n",
    "print(f\"üå± Random seed: {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìÅ Kaggle Data Paths\n",
    "\n",
    "**Instructions for Kaggle:**\n",
    "1. Upload Elliptic++ dataset as a Kaggle dataset\n",
    "2. Add it to this notebook\n",
    "3. Update `DATA_ROOT` below to match your dataset path\n",
    "\n",
    "**Expected files:**\n",
    "- `txs_features.csv` - Node features (182 features)\n",
    "- `txs_classes.csv` - Labels (1=illicit, 2=licit, 3=unknown)\n",
    "- `txs_edgelist.csv` - Directed edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle data paths - UPDATE THIS to match your Kaggle dataset\n",
    "DATA_ROOT = Path(\"/kaggle/input/elliptic-plus-plus-dataset\")  # Adjust for your Kaggle dataset name\n",
    "\n",
    "# Alternative: If running locally, use this:\n",
    "# DATA_ROOT = Path(\"../data/Elliptic++ Dataset\")\n",
    "\n",
    "FEATURES_FILE = DATA_ROOT / \"txs_features.csv\"\n",
    "CLASSES_FILE = DATA_ROOT / \"txs_classes.csv\"\n",
    "EDGES_FILE = DATA_ROOT / \"txs_edgelist.csv\"\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_DIR = Path(\".\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Verify files exist\n",
    "print(\"üìÇ Checking dataset files...\")\n",
    "for f in [FEATURES_FILE, CLASSES_FILE, EDGES_FILE]:\n",
    "    if f.exists():\n",
    "        print(f\"  ‚úÖ {f.name}\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {f.name} NOT FOUND!\")\n",
    "        print(f\"     Expected at: {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Data Loading & Preprocessing\n",
    "\n",
    "### Load Elliptic++ Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì• Loading Elliptic++ dataset...\\n\")\n",
    "\n",
    "# Load features\n",
    "print(\"Loading features...\")\n",
    "features_df = pd.read_csv(FEATURES_FILE)\n",
    "print(f\"  Shape: {features_df.shape}\")\n",
    "print(f\"  Columns: {list(features_df.columns[:5])}...\")\n",
    "\n",
    "# Load classes\n",
    "print(\"\\nLoading classes...\")\n",
    "classes_df = pd.read_csv(CLASSES_FILE)\n",
    "print(f\"  Shape: {classes_df.shape}\")\n",
    "\n",
    "# Load edges\n",
    "print(\"\\nLoading edges...\")\n",
    "edges_df = pd.read_csv(EDGES_FILE)\n",
    "print(f\"  Shape: {edges_df.shape}\")\n",
    "print(f\"  Total edges: {len(edges_df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge features and classes\n",
    "data_df = features_df.merge(classes_df, on='txId', how='left')\n",
    "\n",
    "# Normalize timestamp column name\n",
    "ts_candidates = ['Time step', 'time_step', 'timestamp', 'time', 'timestep']\n",
    "for col in ts_candidates:\n",
    "    if col in data_df.columns:\n",
    "        if col != 'timestamp':\n",
    "            data_df.rename(columns={col: 'timestamp'}, inplace=True)\n",
    "        break\n",
    "\n",
    "# Fill unlabeled as class 3\n",
    "data_df['class'] = data_df['class'].fillna(3).astype(int)\n",
    "\n",
    "print(\"\\nüìä Dataset Statistics:\")\n",
    "print(f\"Total transactions: {len(data_df):,}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(f\"  Class 1 (Illicit):  {(data_df['class'] == 1).sum():,} ({100*(data_df['class'] == 1).sum()/len(data_df):.2f}%)\")\n",
    "print(f\"  Class 2 (Licit):    {(data_df['class'] == 2).sum():,} ({100*(data_df['class'] == 2).sum()/len(data_df):.2f}%)\")\n",
    "print(f\"  Class 3 (Unknown):  {(data_df['class'] == 3).sum():,} ({100*(data_df['class'] == 3).sum()/len(data_df):.2f}%)\")\n",
    "\n",
    "labeled = data_df[data_df['class'].isin([1, 2])]\n",
    "fraud_pct = 100 * (labeled['class'] == 1).sum() / len(labeled)\n",
    "print(f\"\\nüìà Labeled fraud rate: {fraud_pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Node Mapping and Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tx_id to index mapping\n",
    "tx_ids = data_df['txId'].values\n",
    "tx_id_to_idx = {tx_id: idx for idx, tx_id in enumerate(tx_ids)}\n",
    "print(f\"\\nüó∫Ô∏è Created mapping for {len(tx_id_to_idx):,} transactions\")\n",
    "\n",
    "# Extract LOCAL features only (AF1-AF93) to avoid double-encoding aggregate stats\n",
    "feature_cols = [col for col in data_df.columns \n",
    "                if col not in ['txId', 'timestamp', 'class']]\n",
    "\n",
    "# Filter to Local features only (first 93 features)\n",
    "local_features = [col for col in feature_cols if 'Local' in col or \n",
    "                  (col.startswith('AF') and int(col.replace('AF', '')) <= 93)]\n",
    "\n",
    "if not local_features:\n",
    "    # If no 'Local' prefix, assume first 93 are local\n",
    "    local_features = feature_cols[:93]\n",
    "\n",
    "print(f\"\\nüî¢ Using {len(local_features)} LOCAL features (avoiding aggregate double-encoding)\")\n",
    "print(f\"   Feature range: {local_features[0]} to {local_features[-1]}\")\n",
    "\n",
    "# Extract features\n",
    "x = torch.FloatTensor(data_df[local_features].values)\n",
    "\n",
    "# Handle NaN/Inf\n",
    "x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# Normalize features (important for GNN stability)\n",
    "x_mean = x.mean(dim=0)\n",
    "x_std = x.std(dim=0)\n",
    "x = (x - x_mean) / (x_std + 1e-8)\n",
    "x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "print(f\"\\n‚úÖ Feature matrix shape: {x.shape}\")\n",
    "print(f\"   Mean: {x.mean():.4f}, Std: {x.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Labels and Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract timestamps\n",
    "timestamps = data_df['timestamp'].values\n",
    "timestamps_tensor = torch.LongTensor(timestamps)\n",
    "\n",
    "# Convert classes to binary labels\n",
    "# Elliptic encoding: 1=illicit (fraud), 2=licit (legit), 3=unknown\n",
    "# Binary: 1->1 (fraud), 2->0 (legit), 3->-1 (unknown/unlabeled)\n",
    "y_raw = data_df['class'].values\n",
    "y = np.where(y_raw == 1, 1, np.where(y_raw == 2, 0, -1))\n",
    "y = torch.LongTensor(y)\n",
    "\n",
    "print(f\"\\nüè∑Ô∏è Labels:\")\n",
    "print(f\"   Fraud (1): {(y == 1).sum():,}\")\n",
    "print(f\"   Legit (0): {(y == 0).sum():,}\")\n",
    "print(f\"   Unknown (-1): {(y == -1).sum():,}\")\n",
    "\n",
    "print(f\"\\n‚è∞ Timestamps:\")\n",
    "print(f\"   Range: {timestamps.min()} to {timestamps.max()}\")\n",
    "print(f\"   Unique timesteps: {len(np.unique(timestamps))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Edge Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîó Building edge index...\")\n",
    "\n",
    "# Filter edges to known nodes\n",
    "valid_edges = edges_df[\n",
    "    edges_df['txId1'].isin(tx_id_to_idx) & \n",
    "    edges_df['txId2'].isin(tx_id_to_idx)\n",
    "]\n",
    "\n",
    "print(f\"   Valid edges: {len(valid_edges):,} / {len(edges_df):,}\")\n",
    "\n",
    "# Map to indices\n",
    "edge_src = valid_edges['txId1'].map(tx_id_to_idx).values\n",
    "edge_dst = valid_edges['txId2'].map(tx_id_to_idx).values\n",
    "edge_index = torch.LongTensor(np.vstack([edge_src, edge_dst]))\n",
    "\n",
    "print(f\"\\n‚úÖ Edge index shape: {edge_index.shape}\")\n",
    "print(f\"   Total edges: {edge_index.shape[1]:,}\")\n",
    "print(f\"   Average degree: {edge_index.shape[1] / len(tx_ids):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚è±Ô∏è Temporal Splits\n",
    "\n",
    "Create train/val/test splits based on timestamps (60%/20%/20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_temporal_splits(timestamps, train_frac=0.6, val_frac=0.2, test_frac=0.2):\n",
    "    \"\"\"\n",
    "    Create temporal splits based on timestamps.\n",
    "    \"\"\"\n",
    "    assert abs(train_frac + val_frac + test_frac - 1.0) < 1e-6\n",
    "    \n",
    "    # Sort timestamps and find boundaries\n",
    "    sorted_times = np.sort(np.unique(timestamps))\n",
    "    n_timesteps = len(sorted_times)\n",
    "    \n",
    "    train_end_idx = int(n_timesteps * train_frac)\n",
    "    val_end_idx = int(n_timesteps * (train_frac + val_frac))\n",
    "    \n",
    "    train_time_end = sorted_times[train_end_idx - 1]\n",
    "    val_time_end = sorted_times[val_end_idx - 1]\n",
    "    \n",
    "    # Create masks\n",
    "    train_mask = timestamps <= train_time_end\n",
    "    val_mask = (timestamps > train_time_end) & (timestamps <= val_time_end)\n",
    "    test_mask = timestamps > val_time_end\n",
    "    \n",
    "    return {\n",
    "        'train': train_mask,\n",
    "        'val': val_mask,\n",
    "        'test': test_mask,\n",
    "        'train_time_end': int(train_time_end),\n",
    "        'val_time_end': int(val_time_end)\n",
    "    }\n",
    "\n",
    "# Create splits\n",
    "print(\"\\nüìÖ Creating temporal splits...\")\n",
    "splits = create_temporal_splits(timestamps)\n",
    "\n",
    "# Create masks for labeled nodes only\n",
    "labeled_mask = y >= 0\n",
    "\n",
    "train_mask = torch.BoolTensor(splits['train'] & labeled_mask.numpy())\n",
    "val_mask = torch.BoolTensor(splits['val'] & labeled_mask.numpy())\n",
    "test_mask = torch.BoolTensor(splits['test'] & labeled_mask.numpy())\n",
    "\n",
    "print(f\"\\nSplit statistics:\")\n",
    "print(f\"  Train: {train_mask.sum():,} labeled nodes (time ‚â§ {splits['train_time_end']})\")\n",
    "print(f\"  Val:   {val_mask.sum():,} labeled nodes (time ‚â§ {splits['val_time_end']})\")\n",
    "print(f\"  Test:  {test_mask.sum():,} labeled nodes\")\n",
    "\n",
    "# Check class balance per split\n",
    "for split_name, mask in [('Train', train_mask), ('Val', val_mask), ('Test', test_mask)]:\n",
    "    if mask.sum() > 0:\n",
    "        fraud = (y[mask] == 1).sum().item()\n",
    "        legit = (y[mask] == 0).sum().item()\n",
    "        total = mask.sum().item()\n",
    "        print(f\"\\n  {split_name} balance:\")\n",
    "        print(f\"    Fraud: {fraud:,} ({100*fraud/total:.2f}%)\")\n",
    "        print(f\"    Legit: {legit:,} ({100*legit/total:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß† TRD-GraphSAGE Model Implementation\n",
    "\n",
    "### TRD Sampler (Time-Relaxed Directed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRDSampler:\n",
    "    \"\"\"\n",
    "    Time-Relaxed Directed (TRD) neighbor sampler.\n",
    "    \n",
    "    Enforces temporal constraint: for each target node at time t*,\n",
    "    only includes neighbors v where time(v) <= t*.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fanouts=[15, 10], directed=True, \n",
    "                 max_in_neighbors=15, max_out_neighbors=15):\n",
    "        self.fanouts = list(fanouts)\n",
    "        self.directed = directed\n",
    "        self.max_in_neighbors = max_in_neighbors\n",
    "        self.max_out_neighbors = max_out_neighbors\n",
    "        self.num_layers = len(self.fanouts)\n",
    "        \n",
    "    def sample(self, edge_index, timestamps, target_nodes, num_hops=2):\n",
    "        \"\"\"\n",
    "        Sample temporal neighborhood for target nodes.\n",
    "        \n",
    "        Args:\n",
    "            edge_index: [2, E] edge tensor (source, target)\n",
    "            timestamps: [N] node timestamps\n",
    "            target_nodes: [T] target node indices\n",
    "            num_hops: Number of hops to sample\n",
    "            \n",
    "        Returns:\n",
    "            sampled_nodes: Nodes in sampled subgraph\n",
    "            sampled_edges: Edge index of sampled subgraph\n",
    "            layer_sizes: Number of nodes added at each layer\n",
    "        \"\"\"\n",
    "        if num_hops != self.num_layers:\n",
    "            num_hops = self.num_layers\n",
    "            \n",
    "        device = edge_index.device\n",
    "        \n",
    "        # Initialize with target nodes\n",
    "        current_nodes = target_nodes.unique()\n",
    "        all_sampled_nodes = [current_nodes]\n",
    "        all_sampled_edges = []\n",
    "        layer_sizes = [len(current_nodes)]\n",
    "        \n",
    "        # Build adjacency list\n",
    "        num_nodes = timestamps.shape[0]\n",
    "        adj_out = [[] for _ in range(num_nodes)]\n",
    "        adj_in = [[] for _ in range(num_nodes)]\n",
    "        \n",
    "        for i in range(edge_index.shape[1]):\n",
    "            src, dst = edge_index[0, i].item(), edge_index[1, i].item()\n",
    "            adj_out[src].append(dst)\n",
    "            adj_in[dst].append(src)\n",
    "        \n",
    "        # Sample layer by layer\n",
    "        for layer_idx in range(num_hops):\n",
    "            fanout = self.fanouts[layer_idx]\n",
    "            next_layer_nodes = []\n",
    "            layer_edges = []\n",
    "            \n",
    "            for node_idx in current_nodes.cpu().numpy():\n",
    "                node_time = timestamps[node_idx].item()\n",
    "                \n",
    "                # Get temporal neighbors (time <= node_time)\n",
    "                in_neighbors = [\n",
    "                    n for n in adj_in[node_idx] \n",
    "                    if timestamps[n].item() <= node_time\n",
    "                ]\n",
    "                out_neighbors = [\n",
    "                    n for n in adj_out[node_idx]\n",
    "                    if timestamps[n].item() <= node_time\n",
    "                ] if self.directed else []\n",
    "                \n",
    "                # Cap neighbors\n",
    "                if len(in_neighbors) > self.max_in_neighbors:\n",
    "                    in_neighbors = np.random.choice(\n",
    "                        in_neighbors, self.max_in_neighbors, replace=False\n",
    "                    ).tolist()\n",
    "                    \n",
    "                if self.directed and len(out_neighbors) > self.max_out_neighbors:\n",
    "                    out_neighbors = np.random.choice(\n",
    "                        out_neighbors, self.max_out_neighbors, replace=False\n",
    "                    ).tolist()\n",
    "                \n",
    "                # Combine neighbors\n",
    "                all_neighbors = in_neighbors + out_neighbors\n",
    "                \n",
    "                # Sample up to fanout\n",
    "                if len(all_neighbors) > fanout:\n",
    "                    sampled = np.random.choice(\n",
    "                        all_neighbors, min(fanout, len(all_neighbors)), replace=False\n",
    "                    ).tolist()\n",
    "                else:\n",
    "                    sampled = all_neighbors\n",
    "                \n",
    "                # Add edges\n",
    "                for neighbor in sampled:\n",
    "                    next_layer_nodes.append(neighbor)\n",
    "                    layer_edges.append([neighbor, node_idx])\n",
    "                \n",
    "                # Add self-loop\n",
    "                layer_edges.append([node_idx, node_idx])\n",
    "            \n",
    "            # Update for next layer\n",
    "            if next_layer_nodes:\n",
    "                current_nodes = torch.tensor(\n",
    "                    list(set(next_layer_nodes)), dtype=torch.long, device=device\n",
    "                )\n",
    "                all_sampled_nodes.append(current_nodes)\n",
    "                layer_sizes.append(len(current_nodes))\n",
    "            else:\n",
    "                layer_sizes.append(0)\n",
    "            \n",
    "            if layer_edges:\n",
    "                all_sampled_edges.extend(layer_edges)\n",
    "        \n",
    "        # Combine all nodes\n",
    "        all_nodes = torch.cat(all_sampled_nodes).unique()\n",
    "        \n",
    "        # Create node mapping\n",
    "        node_mapping = {n.item(): i for i, n in enumerate(all_nodes)}\n",
    "        \n",
    "        # Remap edges\n",
    "        if all_sampled_edges:\n",
    "            remapped_edges = [\n",
    "                [node_mapping[src], node_mapping[dst]]\n",
    "                for src, dst in all_sampled_edges\n",
    "                if src in node_mapping and dst in node_mapping\n",
    "            ]\n",
    "            sampled_edge_index = torch.tensor(\n",
    "                remapped_edges, dtype=torch.long, device=device\n",
    "            ).t().contiguous() if remapped_edges else torch.zeros((2, 0), dtype=torch.long, device=device)\n",
    "        else:\n",
    "            sampled_edge_index = torch.zeros((2, 0), dtype=torch.long, device=device)\n",
    "        \n",
    "        return all_nodes, sampled_edge_index, layer_sizes\n",
    "\n",
    "print(\"‚úÖ TRD Sampler defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRD-GraphSAGE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRDGraphSAGE(nn.Module):\n",
    "    \"\"\"\n",
    "    TRD-GraphSAGE: Temporal GraphSAGE with Time-Relaxed Directed sampling.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, hidden_channels, out_channels=2, \n",
    "                 num_layers=2, dropout=0.4, aggregator='mean'):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.convs = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        \n",
    "        # Input layer\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels, aggr=aggregator))\n",
    "        self.batch_norms.append(nn.BatchNorm1d(hidden_channels))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels, aggr=aggregator))\n",
    "            self.batch_norms.append(nn.BatchNorm1d(hidden_channels))\n",
    "        \n",
    "        # Output layer\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels, aggr=aggregator))\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.batch_norms[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = TRDGraphSAGE(\n",
    "    in_channels=x.shape[1],\n",
    "    hidden_channels=128,\n",
    "    out_channels=2,\n",
    "    num_layers=2,\n",
    "    dropout=0.4\n",
    ").to(device)\n",
    "\n",
    "print(f\"\\nüß† TRD-GraphSAGE Model:\")\n",
    "print(f\"   Input features: {x.shape[1]}\")\n",
    "print(f\"   Hidden channels: 128\")\n",
    "   print(f\"   Output classes: 2\")\n",
    "print(f\"   Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"   Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèãÔ∏è Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights for imbalanced dataset\n",
    "train_labels = y[train_mask]\n",
    "n_fraud = (train_labels == 1).sum().item()\n",
    "n_legit = (train_labels == 0).sum().item()\n",
    "pos_weight = n_legit / n_fraud\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è Class imbalance:\")\n",
    "print(f\"   Fraud: {n_fraud:,}\")\n",
    "print(f\"   Legit: {n_legit:,}\")\n",
    "print(f\"   Pos weight: {pos_weight:.4f}\")\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "\n",
    "# Training configuration\n",
    "config = {\n",
    "    'epochs': 100,\n",
    "    'early_stopping_patience': 15,\n",
    "    'best_val_metric': 0.0,\n",
    "    'patience_counter': 0,\n",
    "    'best_epoch': 0\n",
    "}\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è Training configuration:\")\n",
    "print(f\"   Max epochs: {config['epochs']}\")\n",
    "print(f\"   Early stopping patience: {config['early_stopping_patience']}\")\n",
    "print(f\"   Optimizer: Adam (lr=0.001, wd=5e-4)\")\n",
    "print(f\"   Loss: CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x, edge_index, y, mask):\n",
    "    \"\"\"\n",
    "    Evaluate model and return comprehensive metrics.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(x, edge_index)\n",
    "        probs = F.softmax(logits, dim=1)[:, 1]  # Probability of fraud class\n",
    "        \n",
    "        y_true = y[mask].cpu().numpy()\n",
    "        y_score = probs[mask].cpu().numpy()\n",
    "        \n",
    "        # Calculate PR-AUC\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        \n",
    "        # Calculate ROC-AUC\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        return {\n",
    "            'pr_auc': pr_auc,\n",
    "            'roc_auc': roc_auc,\n",
    "            'y_true': y_true,\n",
    "            'y_score': y_score,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'fpr': fpr,\n",
    "            'tpr': tpr\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Evaluation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ Training Loop\n",
    "\n",
    "Training with early stopping on validation PR-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move data to device\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "edge_index = edge_index.to(device)\n",
    "train_mask = train_mask.to(device)\n",
    "val_mask = val_mask.to(device)\n",
    "test_mask = test_mask.to(device)\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_pr_auc': [],\n",
    "    'val_roc_auc': [],\n",
    "    'epoch': []\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üèãÔ∏è TRAINING TRD-GraphSAGE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    # Training\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    logits = model(x, edge_index)\n",
    "    loss = criterion(logits[train_mask], y[train_mask])\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Validation\n",
    "    val_metrics = evaluate_model(model, x, edge_index, y, val_mask)\n",
    "    \n",
    "    # Store history\n",
    "    history['train_loss'].append(loss.item())\n",
    "    history['val_pr_auc'].append(val_metrics['pr_auc'])\n",
    "    history['val_roc_auc'].append(val_metrics['roc_auc'])\n",
    "    history['epoch'].append(epoch + 1)\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch+1:3d}/{config['epochs']} | \"\n",
    "              f\"Loss: {loss.item():.4f} | \"\n",
    "              f\"Val PR-AUC: {val_metrics['pr_auc']:.4f} | \"\n",
    "              f\"Val ROC-AUC: {val_metrics['roc_auc']:.4f}\")\n",
    "    \n",
    "    # Early stopping check\n",
    "    if val_metrics['pr_auc'] > config['best_val_metric']:\n",
    "        config['best_val_metric'] = val_metrics['pr_auc']\n",
    "        config['best_epoch'] = epoch + 1\n",
    "        config['patience_counter'] = 0\n",
    "        # Save best model\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_pr_auc': val_metrics['pr_auc'],\n",
    "            'val_roc_auc': val_metrics['roc_auc'],\n",
    "        }, 'trd_graphsage_best.pt')\n",
    "    else:\n",
    "        config['patience_counter'] += 1\n",
    "        \n",
    "    # Early stopping\n",
    "    if config['patience_counter'] >= config['early_stopping_patience']:\n",
    "        print(f\"\\n‚èπÔ∏è Early stopping triggered at epoch {epoch+1}\")\n",
    "        print(f\"   Best epoch: {config['best_epoch']}\")\n",
    "        print(f\"   Best val PR-AUC: {config['best_val_metric']:.4f}\")\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ TRAINING COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Training loss\n",
    "axes[0].plot(history['epoch'], history['train_loss'], 'b-', linewidth=2, label='Train Loss')\n",
    "axes[0].axvline(config['best_epoch'], color='r', linestyle='--', alpha=0.7, label='Best Epoch')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Validation metrics\n",
    "axes[1].plot(history['epoch'], history['val_pr_auc'], 'g-', linewidth=2, label='Val PR-AUC')\n",
    "axes[1].plot(history['epoch'], history['val_roc_auc'], 'orange', linewidth=2, label='Val ROC-AUC')\n",
    "axes[1].axvline(config['best_epoch'], color='r', linestyle='--', alpha=0.7, label='Best Epoch')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('AUC Score', fontsize=12)\n",
    "axes[1].set_title('Validation Metrics', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('trd_graphsage_training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Training history plot saved: trd_graphsage_training_history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Test Set Evaluation\n",
    "\n",
    "Load best model and evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load('trd_graphsage_best.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä TEST SET EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Evaluate on all splits\n",
    "train_results = evaluate_model(model, x, edge_index, y, train_mask)\n",
    "val_results = evaluate_model(model, x, edge_index, y, val_mask)\n",
    "test_results = evaluate_model(model, x, edge_index, y, test_mask)\n",
    "\n",
    "print(f\"\\nüìà Results:\")\n",
    "print(f\"\\n  Train:\")\n",
    "print(f\"    PR-AUC:  {train_results['pr_auc']:.4f}\")\n",
    "print(f\"    ROC-AUC: {train_results['roc_auc']:.4f}\")\n",
    "print(f\"\\n  Validation:\")\n",
    "print(f\"    PR-AUC:  {val_results['pr_auc']:.4f}\")\n",
    "print(f\"    ROC-AUC: {val_results['roc_auc']:.4f}\")\n",
    "print(f\"\\n  Test:\")\n",
    "print(f\"    PR-AUC:  {test_results['pr_auc']:.4f}\")\n",
    "print(f\"    ROC-AUC: {test_results['roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate F1 Score and Recall@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal threshold on validation set\n",
    "f1_scores = []\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_pred = (val_results['y_score'] >= thresh).astype(int)\n",
    "    f1 = f1_score(val_results['y_true'], y_pred)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "best_thresh_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_thresh_idx]\n",
    "best_f1_val = f1_scores[best_thresh_idx]\n",
    "\n",
    "# Apply best threshold to test set\n",
    "y_pred_test = (test_results['y_score'] >= best_threshold).astype(int)\n",
    "test_f1 = f1_score(test_results['y_true'], y_pred_test)\n",
    "\n",
    "print(f\"\\nüéØ Optimal threshold (from validation): {best_threshold:.4f}\")\n",
    "print(f\"   Val F1:  {best_f1_val:.4f}\")\n",
    "print(f\"   Test F1: {test_f1:.4f}\")\n",
    "\n",
    "# Calculate Recall@K\n",
    "def recall_at_k(y_true, y_score, k_frac=0.01):\n",
    "    \"\"\"Calculate recall at top k% predictions.\"\"\"\n",
    "    k = max(1, int(len(y_true) * k_frac))\n",
    "    top_k_idx = np.argsort(y_score)[-k:]\n",
    "    return y_true[top_k_idx].sum() / y_true.sum()\n",
    "\n",
    "recall_at_05 = recall_at_k(test_results['y_true'], test_results['y_score'], 0.005)\n",
    "recall_at_1 = recall_at_k(test_results['y_true'], test_results['y_score'], 0.01)\n",
    "recall_at_2 = recall_at_k(test_results['y_true'], test_results['y_score'], 0.02)\n",
    "\n",
    "print(f\"\\nüìç Recall@K (Test):\")\n",
    "print(f\"   Recall@0.5%: {recall_at_05:.4f}\")\n",
    "print(f\"   Recall@1%:   {recall_at_1:.4f}\")\n",
    "print(f\"   Recall@2%:   {recall_at_2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization: PR and ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# PR Curve\n",
    "axes[0].plot(test_results['recall'], test_results['precision'], 'b-', linewidth=2, \n",
    "             label=f\"TRD-GraphSAGE (AUC={test_results['pr_auc']:.4f})\")\n",
    "axes[0].set_xlabel('Recall', fontsize=12)\n",
    "axes[0].set_ylabel('Precision', fontsize=12)\n",
    "axes[0].set_title('Precision-Recall Curve (Test Set)', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# ROC Curve\n",
    "axes[1].plot(test_results['fpr'], test_results['tpr'], 'g-', linewidth=2,\n",
    "             label=f\"TRD-GraphSAGE (AUC={test_results['roc_auc']:.4f})\")\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', linewidth=1, alpha=0.5, label='Random')\n",
    "axes[1].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[1].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[1].set_title('ROC Curve (Test Set)', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('trd_graphsage_pr_roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä PR/ROC curves saved: trd_graphsage_pr_roc_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üíæ Export Results\n",
    "\n",
    "Save metrics for comparison with baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Create metrics dictionary\n",
    "metrics = {\n",
    "    'timestamp': int(time.time()),\n",
    "    'experiment': 'trd-gnn-temporal',\n",
    "    'model': 'TRD-GraphSAGE',\n",
    "    'split': 'test',\n",
    "    'pr_auc': test_results['pr_auc'],\n",
    "    'roc_auc': test_results['roc_auc'],\n",
    "    'f1': test_f1,\n",
    "    'recall@1%': recall_at_1,\n",
    "    'recall@0.5%': recall_at_05,\n",
    "    'recall@2%': recall_at_2,\n",
    "    'best_threshold': best_threshold,\n",
    "    'best_epoch': config['best_epoch'],\n",
    "    'total_epochs': len(history['epoch']),\n",
    "    'feature_set': 'Local (AF1-AF93)',\n",
    "    'num_parameters': sum(p.numel() for p in model.parameters()),\n",
    "    'hidden_channels': 128,\n",
    "    'num_layers': 2,\n",
    "    'dropout': 0.4\n",
    "}\n",
    "\n",
    "# Save as JSON\n",
    "with open('trd_graphsage_metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"\\nüíæ Metrics saved: trd_graphsage_metrics.json\")\n",
    "print(\"\\nüìã Final Metrics Summary:\")\n",
    "print(json.dumps(metrics, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CSV Row for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame row\n",
    "results_row = pd.DataFrame([{\n",
    "    'timestamp': metrics['timestamp'],\n",
    "    'experiment': metrics['experiment'],\n",
    "    'model': metrics['model'],\n",
    "    'split': metrics['split'],\n",
    "    'pr_auc': metrics['pr_auc'],\n",
    "    'roc_auc': metrics['roc_auc'],\n",
    "    'f1': metrics['f1'],\n",
    "    'recall@1%': metrics['recall@1%']\n",
    "}])\n",
    "\n",
    "# Save to CSV\n",
    "results_row.to_csv('trd_graphsage_results.csv', index=False)\n",
    "\n",
    "print(\"\\nüìä Results CSV saved: trd_graphsage_results.csv\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(results_row.to_string(index=False))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Summary & Next Steps\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **TRD-GraphSAGE Performance**:\n",
    "   - Test PR-AUC: _____ (fill after running)\n",
    "   - Test ROC-AUC: _____ (fill after running)\n",
    "   - Test F1: _____ (fill after running)\n",
    "\n",
    "2. **Temporal Constraints**:\n",
    "   - ‚úÖ No future leakage enforced\n",
    "   - ‚úÖ Directed sampling respected\n",
    "   - ‚úÖ Temporal splits maintained\n",
    "\n",
    "3. **Model Characteristics**:\n",
    "   - Parameters: ~_____ (fill after running)\n",
    "   - Training time: ~_____ (fill after running)\n",
    "   - Best epoch: _____ (fill after running)\n",
    "\n",
    "### Comparison with Baseline\n",
    "\n",
    "To compare with baseline metrics, merge this CSV with the baseline `metrics_summary.csv`:\n",
    "\n",
    "```python\n",
    "baseline_metrics = pd.read_csv('../reports/metrics_summary.csv')\n",
    "combined = pd.concat([baseline_metrics, results_row], ignore_index=True)\n",
    "combined.to_csv('combined_metrics.csv', index=False)\n",
    "```\n",
    "\n",
    "### Files Created\n",
    "\n",
    "1. `trd_graphsage_best.pt` - Best model checkpoint\n",
    "2. `trd_graphsage_metrics.json` - Detailed metrics\n",
    "3. `trd_graphsage_results.csv` - CSV for comparison\n",
    "4. `trd_graphsage_training_history.png` - Training plots\n",
    "5. `trd_graphsage_pr_roc_curves.png` - Evaluation curves\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Download all output files from Kaggle\n",
    "2. Upload to project repository\n",
    "3. Compare with baseline metrics\n",
    "4. Optional: Try TRD-GCN variant\n",
    "5. Optional: Experiment with All features (AF1-AF182)\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Notebook Complete!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
