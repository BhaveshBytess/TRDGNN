{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E9: Wallet Fusion (FAST VERSION - No PyG Install)\n",
    "\n",
    "**Goal:** Combine pre-extracted E7-A3 embeddings with tabular features using XGBoost\n",
    "\n",
    "**Key advantage:** No PyTorch Geometric installation needed! Just load pre-saved embeddings.\n",
    "\n",
    "**Date:** November 11, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup & Imports (No PyG!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_auc_score, f1_score, roc_curve\n",
    "import xgboost as xgb\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"✓ Libraries loaded (no PyG needed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Pre-extracted Embeddings\n",
    "\n",
    "**NOTE:** Upload `e7_tx_embeddings.npy` and `e7_addr_embeddings.npy` to your Kaggle dataset.\n",
    "\n",
    "If you don't have these, use the full version notebook to extract them once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-extracted embeddings (MUCH FASTER!)\n",
    "print(\"Loading pre-extracted embeddings...\")\n",
    "\n",
    "tx_embeddings = np.load('/kaggle/input/a3-embeddings/e7_tx_embeddings.npy')\n",
    "addr_embeddings = np.load('/kaggle/input/a3-embeddings/e7_addr_embeddings.npy')\n",
    "\n",
    "print(f\"✓ Embeddings loaded:\")\n",
    "print(f\"  Transaction: {tx_embeddings.shape}\")\n",
    "print(f\"  Address: {addr_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Labels & Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading labels and splits...\")\n",
    "\n",
    "labels_df = pd.read_csv('/kaggle/input/elliptic-plus-plus/txs_classes.csv')\n",
    "with open('/kaggle/input/elliptic-splits/splits.json') as f:\n",
    "    splits = json.load(f)\n",
    "\n",
    "# Convert to binary\n",
    "labels = labels_df['class'].values\n",
    "y = (labels == 1).astype(int)\n",
    "\n",
    "# Create masks\n",
    "train_mask = np.array(splits['train'])\n",
    "val_mask = np.array(splits['val'])\n",
    "test_mask = np.array(splits['test'])\n",
    "\n",
    "print(f\"✓ Labels loaded:\")\n",
    "print(f\"  Fraud: {(y==1).sum()}, Licit: {(y==0).sum()}\")\n",
    "print(f\"  Train: {train_mask.sum()}, Val: {val_mask.sum()}, Test: {test_mask.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load Tabular Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading transaction features...\")\n",
    "\n",
    "tx_features_df = pd.read_csv('/kaggle/input/elliptic-plus-plus/txs_features.csv')\n",
    "tx_features = tx_features_df.iloc[:, 2:95].values  # Local features 1-93\n",
    "\n",
    "print(f\"✓ Features loaded: {tx_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Fusion Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating fusion features...\")\n",
    "\n",
    "# Normalize tabular features\n",
    "scaler = StandardScaler()\n",
    "tx_features_norm = scaler.fit_transform(tx_features[train_mask])\n",
    "tx_features_norm_all = scaler.transform(tx_features)\n",
    "\n",
    "# Create fusion: GNN embeddings (128) + Tabular (93) = 221 dims\n",
    "tx_fusion = np.concatenate([tx_embeddings, tx_features_norm_all], axis=1)\n",
    "\n",
    "print(f\"✓ Fusion features: {tx_fusion.shape}\")\n",
    "print(f\"  Embeddings (128) + Tabular (93) = 221 dims\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Train XGBoost Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weight\n",
    "pos_weight = (y[train_mask] == 0).sum() / (y[train_mask] == 1).sum()\n",
    "\n",
    "# XGBoost parameters\n",
    "xgb_params = {\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 100,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'scale_pos_weight': pos_weight,\n",
    "    'random_state': 42,\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "print(f\"✓ XGBoost configured (device: {xgb_params['device']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Tabular Only\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Model 1: Tabular Only\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_tabular = xgb.XGBClassifier(**xgb_params)\n",
    "model_tabular.fit(\n",
    "    tx_features_norm_all[train_mask], \n",
    "    y[train_mask],\n",
    "    eval_set=[(tx_features_norm_all[val_mask], y[val_mask])],\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "pred_tabular = model_tabular.predict_proba(tx_features_norm_all[test_mask])[:, 1]\n",
    "print(\"✓ Tabular model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Embeddings Only\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Model 2: Embeddings Only\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_embeddings = xgb.XGBClassifier(**xgb_params)\n",
    "model_embeddings.fit(\n",
    "    tx_embeddings[train_mask], \n",
    "    y[train_mask],\n",
    "    eval_set=[(tx_embeddings[val_mask], y[val_mask])],\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "pred_embeddings = model_embeddings.predict_proba(tx_embeddings[test_mask])[:, 1]\n",
    "print(\"✓ Embeddings model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Fusion\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Model 3: FUSION (Embeddings + Tabular)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_fusion = xgb.XGBClassifier(**xgb_params)\n",
    "model_fusion.fit(\n",
    "    tx_fusion[train_mask], \n",
    "    y[train_mask],\n",
    "    eval_set=[(tx_fusion[val_mask], y[val_mask])],\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "pred_fusion = model_fusion.predict_proba(tx_fusion[test_mask])[:, 1]\n",
    "print(\"✓ Fusion model trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate & Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred_proba):\n",
    "    \"\"\"Compute PR-AUC, ROC-AUC, F1\"\"\"\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    y_pred_binary = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "    f1 = f1_score(y_true, y_pred_binary)\n",
    "    \n",
    "    return {\n",
    "        'pr_auc': float(pr_auc),\n",
    "        'roc_auc': float(roc_auc),\n",
    "        'f1': float(f1),\n",
    "        'threshold': float(optimal_threshold)\n",
    "    }\n",
    "\n",
    "# Compute metrics\n",
    "y_test = y[test_mask]\n",
    "\n",
    "results = {\n",
    "    'tabular_only': compute_metrics(y_test, pred_tabular),\n",
    "    'embeddings_only': compute_metrics(y_test, pred_embeddings),\n",
    "    'fusion': compute_metrics(y_test, pred_fusion)\n",
    "}\n",
    "\n",
    "# Print results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"E9 WALLET FUSION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name.upper().replace('_', ' ')}:\")\n",
    "    print(f\"  PR-AUC:   {metrics['pr_auc']:.4f}\")\n",
    "    print(f\"  ROC-AUC:  {metrics['roc_auc']:.4f}\")\n",
    "    print(f\"  F1:       {metrics['f1']:.4f}\")\n",
    "\n",
    "# Calculate improvements\n",
    "fusion_vs_tabular = (results['fusion']['pr_auc'] - results['tabular_only']['pr_auc']) / results['tabular_only']['pr_auc'] * 100\n",
    "fusion_vs_embeddings = (results['fusion']['pr_auc'] - results['embeddings_only']['pr_auc']) / results['embeddings_only']['pr_auc'] * 100\n",
    "\n",
    "print(f\"\\n{'-'*70}\")\n",
    "print(f\"FUSION IMPROVEMENT:\")\n",
    "print(f\"  vs Tabular:    {fusion_vs_tabular:+.1f}%\")\n",
    "print(f\"  vs Embeddings: {fusion_vs_embeddings:+.1f}%\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save results\n",
    "with open('e9_fusion_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"\\n✓ Results saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison bar chart\n",
    "sns.set_style('whitegrid')\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "models = ['Tabular\\nOnly', 'Embeddings\\nOnly', 'Fusion']\n",
    "metrics_names = ['PR-AUC', 'ROC-AUC', 'F1']\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "\n",
    "for idx, metric_key in enumerate(['pr_auc', 'roc_auc', 'f1']):\n",
    "    values = [\n",
    "        results['tabular_only'][metric_key],\n",
    "        results['embeddings_only'][metric_key],\n",
    "        results['fusion'][metric_key]\n",
    "    ]\n",
    "    \n",
    "    bars = axes[idx].bar(models, values, color=colors)\n",
    "    axes[idx].set_ylabel(metrics_names[idx], fontsize=12)\n",
    "    axes[idx].set_ylim([0, 1])\n",
    "    axes[idx].set_title(f'{metrics_names[idx]} Comparison', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for bar, val in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        axes[idx].text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                      f'{val:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    best_idx = np.argmax(values)\n",
    "    bars[best_idx].set_edgecolor('gold')\n",
    "    bars[best_idx].set_linewidth(3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('e9_fusion_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"✓ Comparison chart saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR and ROC curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# PR Curves\n",
    "for name, pred, color, label in [\n",
    "    ('tabular', pred_tabular, '#3498db', 'Tabular Only'),\n",
    "    ('embeddings', pred_embeddings, '#e74c3c', 'Embeddings Only'),\n",
    "    ('fusion', pred_fusion, '#2ecc71', 'Fusion')\n",
    "]:\n",
    "    precision, recall, _ = precision_recall_curve(y_test, pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    axes[0].plot(recall, precision, color=color, lw=2.5, \n",
    "                label=f'{label} (PR-AUC={pr_auc:.4f})')\n",
    "\n",
    "axes[0].set_xlabel('Recall', fontsize=12)\n",
    "axes[0].set_ylabel('Precision', fontsize=12)\n",
    "axes[0].set_title('Precision-Recall Curves', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(loc='best', fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# ROC Curves\n",
    "for name, pred, color, label in [\n",
    "    ('tabular', pred_tabular, '#3498db', 'Tabular Only'),\n",
    "    ('embeddings', pred_embeddings, '#e74c3c', 'Embeddings Only'),\n",
    "    ('fusion', pred_fusion, '#2ecc71', 'Fusion')\n",
    "]:\n",
    "    fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    axes[1].plot(fpr, tpr, color=color, lw=2.5, \n",
    "                label=f'{label} (ROC-AUC={roc_auc:.4f})')\n",
    "\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', lw=1, alpha=0.3)\n",
    "axes[1].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[1].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[1].set_title('ROC Curves', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(loc='best', fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('e9_fusion_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"✓ PR/ROC curves saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"E9 WALLET FUSION COMPLETE (FAST VERSION)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n⚡ Total time saved: ~10 minutes (no PyG installation!)\")\n",
    "\n",
    "print(\"\\nKey Finding:\")\n",
    "if results['fusion']['pr_auc'] > max(results['tabular_only']['pr_auc'], results['embeddings_only']['pr_auc']):\n",
    "    print(\"  ⭐ FUSION WINS: GNN + Tabular > Either alone\")\n",
    "    print(f\"  ⭐ Best PR-AUC: {results['fusion']['pr_auc']:.4f}\")\n",
    "else:\n",
    "    best_model = max(results, key=lambda k: results[k]['pr_auc'])\n",
    "    print(f\"  ⭐ {best_model.upper()} WINS: {results[best_model]['pr_auc']:.4f}\")\n",
    "\n",
    "print(\"\\nOutput files:\")\n",
    "print(\"  ✓ e9_fusion_results.json\")\n",
    "print(\"  ✓ e9_fusion_comparison.png\")\n",
    "print(\"  ✓ e9_fusion_curves.png\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
